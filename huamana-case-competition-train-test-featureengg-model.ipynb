{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the two CSV files\n",
    "df_TargetMembers = pd.read_csv('humana_mays_target_members.csv')\n",
    "df_exclude = pd.read_excel('ID_drop.xlsx')\n",
    "\n",
    "# Extract the IDs from exclude.csv\n",
    "exclude_ids = df_exclude['ID'].tolist()\n",
    "\n",
    "# Filter rows from df_data where the ID is not in exclude_ids\n",
    "df_filtered_TargetMembers = df_TargetMembers[~df_TargetMembers['id'].isin(exclude_ids)]\n",
    "\n",
    "print(df_filtered_TargetMembers.head())\n",
    "\n",
    "columns_to_drop = ['plan_category', 'product_type','calendar_year' ]  # Replace with your actual column names\n",
    "final_targetmembers = df_filtered_TargetMembers.drop(columns=columns_to_drop)\n",
    "\n",
    "print(final_targetmembers.head())\n",
    "print(len(final_targetmembers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demographics = pd.read_csv('Demographics.csv')\n",
    "\n",
    "drop_columns = ['riskarr_global','riskarr_rewards']\n",
    "final_demographics = demographics.drop(columns=drop_columns)\n",
    "print(len(final_demographics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_demographics.head(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_csv1 = pd.merge(final_targetmembers, final_demographics, on='id', how='inner')\n",
    "print(final_csv1.head())\n",
    "print(len(final_csv1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "web_activity = pd.read_csv('Web Activity.csv')\n",
    "\n",
    "drop_columns = ['login_count_0','login_count_1', 'login_count_2', 'login_count_3', 'login_count_4', 'login_count_5', 'login_count_6', 'login_count_7', 'login_count_8', 'login_count_9', 'login_count_10', 'login_count_11']\n",
    "final_web_acitvity = web_activity.drop(columns=drop_columns)\n",
    "print(len(final_web_acitvity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_csv3 = pd.merge(final_csv1, final_web_acitvity, on='id', how='inner')\n",
    "print(final_csv3.head())\n",
    "print(len(final_csv3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Specify the columns you want to read\n",
    "columns_to_read = ['rx_overall_dist_gpi6_pmpm_ct', 'rx_overall_net_paid_pmpm_cost', 'rx_tier_1_pmpm_ct', 'rx_tier_2_pmpm_ct', 'id']  # Replace with actual column names\n",
    "\n",
    "# Read only the specified columns\n",
    "df_pharmacy = pd.read_csv('Pharmacy Utilization.csv', usecols=columns_to_read)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df_pharmacy.head())\n",
    "print(len(df_pharmacy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_csv4 = pd.merge(final_csv3, df_pharmacy, on='id', how='inner')\n",
    "print(final_csv4.head())\n",
    "print(len(final_csv4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Specify the columns you want to read\n",
    "columns_to_read = ['total_allowed_pmpm_cost','total_cob_paid_pmpm_cost','total_coins_pmpm_cost','total_copay_pmpm_cost','total_deduct_pmpm_cost',\n",
    "                   'total_ip_acute_admit_days_pmpm','total_ip_ltach_admit_days_pmpm','total_ip_maternity_admit_days_pmpm',\n",
    "                   'total_ip_mhsa_admit_days_pmpm','total_ip_rehab_admit_days_pmpm','total_ip_snf_admit_days_pmpm','total_mbr_resp_pmpm_cost',\n",
    "                   'total_net_paid_pmpm_cost', 'id']  # Replace with actual column names\n",
    "\n",
    "# Read only the specified columns\n",
    "df_cost_and_utilization = pd.read_csv('Cost & Utilization.csv', usecols=columns_to_read)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df_cost_and_utilization.head())\n",
    "print(len(df_cost_and_utilization))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_csv5 = pd.merge(final_csv4, df_cost_and_utilization, on='id', how='inner')\n",
    "print(final_csv5.head())\n",
    "print(len(final_csv5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Specify the columns you want to read\n",
    "columns_to_read = ['cnt_cp_emails_pmpm_ct', 'cnt_cp_print_pmpm_ct','cnt_cp_vat_pmpm_ct','cnt_cp_webstatement_pmpm_ct','id']  # Replace with actual column names\n",
    "\n",
    "# Read only the specified columns\n",
    "df_control_point = pd.read_csv('Control Point.csv', usecols=columns_to_read)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df_control_point.head())\n",
    "\n",
    "final_csv7 = pd.merge(final_csv5, df_control_point, on='id', how='inner')\n",
    "print(final_csv7.head())\n",
    "print(len(final_csv7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Specify the columns you want to read\n",
    "columns_to_read = ['atlas_grocpth14', 'atlas_povertyallagespct', 'atlas_recfacpth14', 'atlas_ffrpth14', 'atlas_fsrpth14', 'cms_tot_ma_payment_amt', \n",
    "                   'cms_tot_partd_payment_amt', 'cci_score', 'dcsi_score','fci_score','cms_frailty_ind','id']  # Replace with actual column names\n",
    "\n",
    "# Read only the specified columns\n",
    "df_additional_features = pd.read_csv('Additional Features.csv', usecols=columns_to_read)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df_additional_features.head())\n",
    "\n",
    "final_csv9 = pd.merge(final_csv7, df_additional_features, on='id', how='inner')\n",
    "print(final_csv9.head())\n",
    "print(len(final_csv9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SKIP THIS STEP!!!!\n",
    "#import pandas as pd\n",
    "\n",
    "# Specify the columns you want to read\n",
    "#columns_to_read = ['hcc_model_type', 'cms_model_vers_cd','id']  # Replace with actual column names\n",
    "\n",
    "# Read only the specified columns\n",
    "#df_member_conditions = pd.read_csv('humana_mays_target_member_conditions.csv', usecols=columns_to_read)\n",
    "\n",
    "# Display the DataFrame\n",
    "#print(df_member_conditions.head())\n",
    "\n",
    "#final_csv10 = pd.merge(final_csv9, df_member_conditions, on='id', how='inner')\n",
    "#print(final_csv10.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Specify the columns you want to read\n",
    "columns_to_read = ['sex_cd', 'age','veteran_ind', 'id','state_of_residence', 'county_of_residence', 'race']  # Replace with actual column names\n",
    "\n",
    "# Read only the specified columns\n",
    "df_member_details = pd.read_csv('humana_mays_target_member_details.csv', usecols=columns_to_read)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df_member_details.head())\n",
    "\n",
    "final_csv11 = pd.merge(final_csv9, df_member_details, on='id', how='inner')\n",
    "print(final_csv11.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(final_csv11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Specify the columns you want to read\n",
    "columns_to_read = ['consec_tenure_month', 'all_mm_tenure', 'tenure_band', 'dual_eligible_ind', 'disabled_ind', 'lis_ind', 'id']  # Replace with actual column names\n",
    "\n",
    "# Read only the specified columns\n",
    "df_member_data = pd.read_csv('MEMBER_DATA.csv', usecols=columns_to_read)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df_member_data.head())\n",
    "\n",
    "final_csv12 = pd.merge(final_csv11, df_member_data, on='id', how='inner')\n",
    "print(final_csv12.head())\n",
    "print(len(final_csv12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the two CSV files\n",
    "df_claims = pd.read_csv('humana_mays_target_member_visit_claims.csv')\n",
    "df_exclude = pd.read_excel('ID_drop.xlsx')\n",
    "\n",
    "# Extract the IDs from exclude.csv\n",
    "exclude_ids = df_exclude['ID'].tolist()\n",
    "\n",
    "# Filter rows from df_data where the ID is not in exclude_ids\n",
    "df_filtered_claims = df_claims[~df_claims['id'].isin(exclude_ids)]\n",
    "\n",
    "print(df_filtered_claims.head())\n",
    "print(len(df_filtered_claims))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming df is your DataFrame and 'column_name' is the column where you want to drop duplicates\n",
    "df_count = df_filtered_claims.drop_duplicates(subset='id')\n",
    "len(df_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SKIP THIS PART!!!\n",
    "#drop_columns = ['dos_year','clm_unique_key','serv_date_skey']\n",
    "#df_claims_mod1 = df_filtered_claims.drop(columns=drop_columns)\n",
    "\n",
    "\n",
    "# List of columns to convert and aggregate\n",
    "#visit_columns = [\n",
    "#    'pcp_visit', 'preventative_visit', 'fqhc_visit', 'physical_therapist_visit', \n",
    "#    'cardiologist_visit', 'gastroenterologist_visit', 'orthopedist_visit', \n",
    "#    'obgyn_visit', 'nephroloogist_visit', 'pulmonologist_visit', \n",
    "#    'urgent_care_visit', 'er_visit'\n",
    "#]\n",
    "\n",
    "# Convert 'Y' to 1 and NaN to 0 for all visit-related columns\n",
    "#df_claims_mod1[visit_columns] = df_claims_mod1[visit_columns].applymap(lambda x: 1 if x == 'Y' else 0 if pd.isna(x) else x)\n",
    "\n",
    "# Now group by 'id' and apply the max function to all visit-related columns\n",
    "#df_claims_mod2 = df_claims_mod1.groupby('id', as_index=False).agg({\n",
    "#    'pcp_visit': 'max',\n",
    "#    'preventative_visit': 'max',\n",
    "#    'fqhc_visit': 'max',\n",
    "#    'physical_therapist_visit': 'max',\n",
    "#    'cardiologist_visit': 'max',\n",
    "#    'gastroenterologist_visit': 'max',\n",
    "#    'orthopedist_visit': 'max',\n",
    "#    'obgyn_visit': 'max',\n",
    "#    'nephroloogist_visit': 'max',\n",
    "#    'pulmonologist_visit': 'max',\n",
    "#    'urgent_care_visit': 'max',\n",
    "#    'er_visit': 'max'\n",
    "#})\n",
    "\n",
    "# Display the result\n",
    "#print(df_claims_mod2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "drop_columns = ['dos_year', 'clm_unique_key', 'serv_date_skey']\n",
    "df_claims_mod1 = df_filtered_claims.drop(columns=drop_columns)\n",
    "\n",
    "# List of columns to convert and aggregate\n",
    "visit_columns = [\n",
    "    'pcp_visit', 'preventative_visit', 'fqhc_visit', 'physical_therapist_visit', \n",
    "    'cardiologist_visit', 'gastroenterologist_visit', 'orthopedist_visit', \n",
    "    'obgyn_visit', 'nephroloogist_visit', 'pulmonologist_visit', \n",
    "    'urgent_care_visit', 'er_visit'\n",
    "]\n",
    "\n",
    "# Replace 'Y' with 1 and NaN with 0 in all visit-related columns\n",
    "df_claims_mod1[visit_columns] = df_claims_mod1[visit_columns].replace({'Y': 1, np.nan: 0})\n",
    "\n",
    "# Replace 'Y' with 1 and NaN with 0 for 'comp_physical_exam' and 'telehealth'\n",
    "df_claims_mod1['comp_physical_exam'] = df_claims_mod1['comp_physical_exam'].replace({'Y': 1, np.nan: 0})\n",
    "df_claims_mod1['telehealth'] = df_claims_mod1['telehealth'].replace({'Y': 1, np.nan: 0})\n",
    "\n",
    "# Now group by 'id' and apply the sum function to count the occurrences of 'Y' (now 1s)\n",
    "df_claims_mod2 = df_claims_mod1.groupby('id', as_index=False).agg({\n",
    "    'pcp_visit': 'sum',\n",
    "    'preventative_visit': 'sum',\n",
    "    'fqhc_visit': 'sum',\n",
    "    'physical_therapist_visit': 'sum',\n",
    "    'cardiologist_visit': 'sum',\n",
    "    'gastroenterologist_visit': 'sum',\n",
    "    'orthopedist_visit': 'sum',\n",
    "    'obgyn_visit': 'sum',\n",
    "    'nephroloogist_visit': 'sum',\n",
    "    'pulmonologist_visit': 'sum',\n",
    "    'urgent_care_visit': 'sum',\n",
    "    'er_visit': 'sum',\n",
    "    'comp_physical_exam': 'sum',\n",
    "    'telehealth': 'sum'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SKIP THIS CODE!!!\n",
    "#visit_columns = ['preventative_visit', 'fqhc_visit', \n",
    "#                 'physical_therapist_visit', 'cardiologist_visit', \n",
    "#                 'gastroenterologist_visit', 'orthopedist_visit', \n",
    "#                 'obgyn_visit', 'nephroloogist_visit', \n",
    "#                 'pulmonologist_visit', 'urgent_care_visit', 'er_visit']\n",
    "\n",
    "#df_claims_mod2['any_visit'] = df_claims_mod2[visit_columns].any(axis=1).astype(int)\n",
    "\n",
    "# Display the DataFrame with the new column\n",
    "#print(df_claims_mod2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visit_columns = ['pcp_visit', 'preventative_visit', 'fqhc_visit', \n",
    "                 'physical_therapist_visit', 'cardiologist_visit', \n",
    "                 'gastroenterologist_visit', 'orthopedist_visit', \n",
    "                 'obgyn_visit', 'nephroloogist_visit', \n",
    "                 'pulmonologist_visit', 'urgent_care_visit', 'er_visit']\n",
    "\n",
    "# Calculate the total sum for each row\n",
    "df_claims_mod2['visit_sum'] = df_claims_mod2[visit_columns].sum(axis=1)\n",
    "\n",
    "# Calculate the proportion for 'pcp_visit' (divide by the row's total sum)\n",
    "df_claims_mod2['pcp_visit'] = df_claims_mod2.apply(\n",
    "    lambda row: row['pcp_visit'] / row['visit_sum'] if row['visit_sum'] != 0 else 0, axis=1\n",
    ")\n",
    "\n",
    "# Calculate the proportion for 'any_visit' (sum of all other visit columns except 'pcp_visit')\n",
    "df_claims_mod2['any_visit'] = df_claims_mod2.apply(\n",
    "    lambda row: (row['visit_sum'] - row['pcp_visit'] * row['visit_sum']) / row['visit_sum'] if row['visit_sum'] != 0 else 0, axis=1\n",
    ")\n",
    "\n",
    "# Drop the 'visit_sum' column as it's no longer needed\n",
    "df_claims_mod2.drop(columns=['visit_sum'], inplace=True)\n",
    "\n",
    "# Select only the columns 'id', 'pcp_visit', and 'any_visit'\n",
    "df_claims_mod2 = df_claims_mod2[['id', 'telehealth', 'comp_physical_exam', 'pcp_visit', 'any_visit']]\n",
    "\n",
    "# Display the updated DataFrame with the proportions\n",
    "print(df_claims_mod2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_claims_mod2['telehealth'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_csv13 = pd.merge(final_csv12, df_claims_mod2[['comp_physical_exam', 'telehealth', 'pcp_visit', 'any_visit','id']], on='id', how='left')\n",
    "print(final_csv13.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the new file path\n",
    "file_path = 'output_file.csv'\n",
    "\n",
    "# Export the DataFrame to CSV\n",
    "final_csv13.to_csv(file_path, index=False)\n",
    "len(final_csv13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(final_csv13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify if the NaN values have been replaced\n",
    "print(final_csv13.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# List of IDs to remove\n",
    "ids_to_remove = [\n",
    "    '11213', '15312', '24355', '27248', '30897', '37749', '38856', '43651', '44040', '52740', \n",
    "    '70801', '70874', '77636', '84215', '90776', '117686', '127668', '136131', '148139', '172735', \n",
    "    '174714', '181494', '185568', '187656', '188948', '214425', '235299', '236544', '251604', \n",
    "    '266712', '268602', '270558', '275700', '277012', '296257', '297226', '303460', '314763', \n",
    "    '341674', '353975', '366639', '366931', '369597', '370367', '445685', '459368', '469314', \n",
    "    '472179', '476553', '485285', '489383', '496151', '507892', '513038', '518238', '550407', \n",
    "    '567466', '569162', '587419', '600722', '613487', '650221', '652835', '661488', '662982', \n",
    "    '664904', '672237', '676885', '677529', '681722', '706067', '740751', '747093', '753950', \n",
    "    '791325', '815736', '818155', '849822', '867290', '869276', '886965', '889997', '919993', \n",
    "    '924675', '955085', '970248', '976976', '988399', '988612', '995242', '995981', '1042666', \n",
    "    '1058269', '1059124', '1060845', '1081172', '1101875', '1109926', '1118209', '1118663', \n",
    "    '1133390', '1150362', '1162956', '1176371', '1177371', '1186397', '1196350', '1233011', \n",
    "    '1236814', '1245702', '1246390', '1254296', '1264345', '1264958', '1266952', '1282167', \n",
    "    '1290723', '1304927', '1311050', '1312541', '1359495', '1369690', '1377618', '1396396', \n",
    "    '1407244', '1410006', '1414364', '1448109', '1454006', '1454218', '1465112', '1482882', \n",
    "    '1525165', '1542308', '1542946', '1544353', '1544890', '1560700', '1590279', '1605752', \n",
    "    '1643814', '1662213', '1677158', '1692936', '1706604', '1711285', '1713363', '1721917', \n",
    "    '1758321', '1760129', '1826569', '1840696', '1850376', '1862272', '1864265', '1870096', \n",
    "    '1875262', '1916863', '1946168', '1960097', '1963722', '1970642', '1973379', '1988762'\n",
    "]\n",
    "\n",
    "temp = final_csv13[final_csv13['id'].isin(ids_to_remove)]\n",
    "print(temp)\n",
    "# Remove rows with these IDs\n",
    "#final_csv13_cleaned = final_csv13[~final_csv13['id'].isin(ids_to_remove)]\n",
    "\n",
    "# Print the resulting DataFrame to verify\n",
    "#print(final_csv13_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify if the NaN values have been replaced\n",
    "print(final_csv13_cleaned.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the columns to check for outliers\n",
    "columns_to_check = ['pcp_visit', 'any_visit', 'riskarr_downside', 'riskarr_upside', 'days_since_last_login', \n",
    "                    'login_pmpm_ct', 'rx_overall_net_paid_pmpm_cost', 'rx_overall_dist_gpi6_pmpm_ct',\n",
    "\t\t\t\t\t'rx_tier_1_pmpm_ct','rx_tier_2_pmpm_ct','total_allowed_pmpm_cost','total_net_paid_pmpm_cost','total_cob_paid_pmpm_cost',\n",
    "                    'total_coins_pmpm_cost','total_copay_pmpm_cost','total_deduct_pmpm_cost','total_mbr_resp_pmpm_cost','total_ip_acute_admit_days_pmpm',\n",
    "                    'total_ip_ltach_admit_days_pmpm','total_ip_maternity_admit_days_pmpm','total_ip_mhsa_admit_days_pmpm','total_ip_rehab_admit_days_pmpm',    \n",
    "                    'total_ip_snf_admit_days_pmpm','atlas_recfacpth14','atlas_ffrpth14','atlas_fsrpth14','atlas_grocpth14','atlas_povertyallagespct',\n",
    "                    'cnt_cp_emails_pmpm_ct','cnt_cp_print_pmpm_ct', 'cnt_cp_vat_pmpm_ct','cnt_cp_webstatement_pmpm_ct', 'cms_frailty_ind', \n",
    "                    'cci_score', 'fci_score', 'dcsi_score','cms_tot_ma_payment_amt','cms_tot_partd_payment_amt','comp_physical_exam', 'telehealth']\n",
    "\n",
    "for column in columns_to_check:\n",
    "    # Replace with median\n",
    "    final_csv13_cleaned[column].fillna(final_csv13_cleaned[column].median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the two CSV files\n",
    "sdh = pd.read_csv('Social Determinants of Health.csv')\n",
    "df_exclude = pd.read_excel('ID_drop.xlsx')\n",
    "\n",
    "# Extract the IDs from exclude.csv\n",
    "exclude_ids = df_exclude['ID'].tolist()\n",
    "\n",
    "# Filter rows from df_data where the ID is not in exclude_ids\n",
    "filtered_sdh = sdh[~sdh['id'].isin(exclude_ids)]\n",
    "\n",
    "columns_to_drop = ['rwjf_uninsured_adults_pct','rwjf_uninsured_child_pct',\n",
    "                   'rwjf_diabetes_monitor_pct','rwjf_flu_vax','rwjf_mammography_pct','rwjf_uninsured_pct','rwjf_drug_overdose_deaths_rate',\n",
    "                   'rwjf_drug_deaths_modl_rate',\n",
    "                   'rwjf_insufficient_sleep_pct','rwjf_limit_hlthy_food_pct','rwjf_mv_deaths_rate','rwjf_teen_births_rate','rwjf_std_infect_rate',\n",
    "                   'rwjf_inactivity_pct','rwjf_alcoholic_pct','rwjf_adult_obesity_pct','rwjf_adult_smoking_pct','rwjf_dui_deaths_pct',\n",
    "                   'rwjf_exercise_access_pct','rwjf_mental_distress_pct','rwjf_physical_distress_pct','rwjf_premature_death_rate','rwjf_poor_men_hlth_days',\n",
    "                   'rwjf_life_expectancy','rwjf_child_mortality','rwjf_infant_mortality',\n",
    "                   'rwjf_poor_health_pct','rwjf_low_birthweight_pct','rwjf_premature_mortality','rwjf_long_commute_alone_pct','rwjf_air_pollute_density',\n",
    "                   'rwjf_drinkwater_violate_ind','rwjf_housing_cost_burden_pct','rwjf_severe_housing_pct','rwjf_broadband_access','rwjf_home_ownership_pct',\n",
    "                   'rwjf_drive_alone_pct','rwjf_disconnect_youth_pct','rwjf_child_free_lunch_pct','rwjf_firearm_fatalities_rate','rwjf_homicides_rate',\n",
    "                   'rwjf_injury_deaths_rate','rwjf_social_associate_rate','rwjf_violent_crime_rate','rwjf_some_college_pct',\n",
    "                   'rwjf_single_parent_pct','rwjf_child_poverty_pct','rwjf_high_school_pct','rwjf_unemploy_pct','rwjf_suicides_rate'] \n",
    "\n",
    "final_sdh = filtered_sdh.drop(columns=columns_to_drop)\n",
    "print(final_sdh.head(1000))\n",
    "print(len(final_sdh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace NaN values with the median for each column\n",
    "for column in final_sdh.columns:\n",
    "    # Replace NaN with the median value of the column\n",
    "    final_sdh[column].fillna(final_sdh[column].median(), inplace=True)\n",
    "\n",
    "final_csv13_sdh = pd.merge(final_csv13_cleaned, final_sdh, on='id', how='left')\n",
    "print(final_csv13_sdh.head(1000))\n",
    "print(len(final_csv13_sdh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify if the NaN values have been replaced\n",
    "print(final_csv13_sdh.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_csv13_sdh.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import IsolationForest\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "import seaborn\n",
    "from collections import Counter\n",
    "\n",
    "#n_estimators = Trees\n",
    "model =  IsolationForest(n_estimators=500, max_samples = 0.8, max_features= 0.8, contamination = 0.01, bootstrap=True)\n",
    "\n",
    "# train isolation forest \n",
    "model.fit(final_csv13_sdh[['pcp_visit', 'any_visit', 'riskarr_downside', 'riskarr_upside', 'days_since_last_login','login_pmpm_ct',\n",
    "                           'rx_overall_net_paid_pmpm_cost', 'rx_overall_dist_gpi6_pmpm_ct',\n",
    "\t\t\t\t\t'rx_tier_1_pmpm_ct','rx_tier_2_pmpm_ct','total_allowed_pmpm_cost','total_net_paid_pmpm_cost','total_cob_paid_pmpm_cost',\n",
    "                    'total_coins_pmpm_cost','total_copay_pmpm_cost','total_deduct_pmpm_cost','total_mbr_resp_pmpm_cost','total_ip_acute_admit_days_pmpm',\n",
    "                    'total_ip_ltach_admit_days_pmpm','total_ip_maternity_admit_days_pmpm','total_ip_mhsa_admit_days_pmpm','total_ip_rehab_admit_days_pmpm',    \n",
    "                    'total_ip_snf_admit_days_pmpm','atlas_recfacpth14','atlas_ffrpth14','atlas_fsrpth14','atlas_grocpth14','atlas_povertyallagespct',\n",
    "                    'cnt_cp_emails_pmpm_ct','cnt_cp_print_pmpm_ct', 'cnt_cp_vat_pmpm_ct','cnt_cp_webstatement_pmpm_ct', 'cms_frailty_ind', \n",
    "                    'cci_score', 'fci_score', 'dcsi_score','cms_tot_ma_payment_amt','cms_tot_partd_payment_amt','comp_physical_exam', 'telehealth',\n",
    "                           'rwjf_preventable_ip_rate','rwjf_healthcare_cost','rwjf_other_pcp','rwjf_pcp_rate','rwjf_dentists_ratio',\n",
    "                           'rwjf_men_hlth_prov_ratio','rwjf_age_gt_65_pct','rwjf_native_race_pct','rwjf_asian_race_pct','rwjf_age_lt_18_pct',\n",
    "                           'rwjf_female_pct','rwjf_hispanic_pct','rwjf_hawaiian_race_pct','rwjf_african_race_pct','rwjf_white_race_pct',\n",
    "                           'rwjf_non_english_pct','rwjf_rural_pct','rwjf_population','rwjf_food_insecurity_pct','rwjf_food_env_inx',\n",
    "                           'rwjf_poor_phy_hlth_days','rwjf_diabetes_pct','rwjf_hiv_rate','rwjf_median_house_income','rwjf_income_inequ_ratio',\n",
    "                           'rwjf_resident_seg_black_inx','rwjf_resident_seg_nonwhite_inx']])\n",
    "\n",
    "# add the data to the main  \n",
    "final_csv13_sdh['anomaly'] = model.predict(final_csv13_sdh[['pcp_visit', 'any_visit', 'riskarr_downside', 'riskarr_upside', 'days_since_last_login', \n",
    "                    'login_pmpm_ct', 'rx_overall_net_paid_pmpm_cost', 'rx_overall_dist_gpi6_pmpm_ct',\n",
    "\t\t\t\t\t'rx_tier_1_pmpm_ct','rx_tier_2_pmpm_ct','total_allowed_pmpm_cost','total_net_paid_pmpm_cost','total_cob_paid_pmpm_cost',\n",
    "                    'total_coins_pmpm_cost','total_copay_pmpm_cost','total_deduct_pmpm_cost','total_mbr_resp_pmpm_cost','total_ip_acute_admit_days_pmpm',\n",
    "                    'total_ip_ltach_admit_days_pmpm','total_ip_maternity_admit_days_pmpm','total_ip_mhsa_admit_days_pmpm','total_ip_rehab_admit_days_pmpm',    \n",
    "                    'total_ip_snf_admit_days_pmpm','atlas_recfacpth14','atlas_ffrpth14','atlas_fsrpth14','atlas_grocpth14','atlas_povertyallagespct',\n",
    "                    'cnt_cp_emails_pmpm_ct','cnt_cp_print_pmpm_ct', 'cnt_cp_vat_pmpm_ct','cnt_cp_webstatement_pmpm_ct', 'cms_frailty_ind', \n",
    "                    'cci_score', 'fci_score', 'dcsi_score','cms_tot_ma_payment_amt','cms_tot_partd_payment_amt','comp_physical_exam', 'telehealth',\n",
    "                           'rwjf_preventable_ip_rate','rwjf_healthcare_cost','rwjf_other_pcp','rwjf_pcp_rate','rwjf_dentists_ratio',\n",
    "                           'rwjf_men_hlth_prov_ratio','rwjf_age_gt_65_pct','rwjf_native_race_pct','rwjf_asian_race_pct','rwjf_age_lt_18_pct',\n",
    "                           'rwjf_female_pct','rwjf_hispanic_pct','rwjf_hawaiian_race_pct','rwjf_african_race_pct','rwjf_white_race_pct',\n",
    "                           'rwjf_non_english_pct','rwjf_rural_pct','rwjf_population','rwjf_food_insecurity_pct','rwjf_food_env_inx',\n",
    "                           'rwjf_poor_phy_hlth_days','rwjf_diabetes_pct','rwjf_hiv_rate','rwjf_median_house_income','rwjf_income_inequ_ratio',\n",
    "                           'rwjf_resident_seg_black_inx','rwjf_resident_seg_nonwhite_inx']])\n",
    "\n",
    "print(np.unique(final_csv13_sdh['anomaly']))\n",
    "\n",
    "count_counter = Counter(model.predict(final_csv13_sdh[['pcp_visit', 'any_visit', 'riskarr_downside', 'riskarr_upside', 'days_since_last_login', \n",
    "                    'login_pmpm_ct', 'rx_overall_net_paid_pmpm_cost', 'rx_overall_dist_gpi6_pmpm_ct',\n",
    "\t\t\t\t\t'rx_tier_1_pmpm_ct','rx_tier_2_pmpm_ct','total_allowed_pmpm_cost','total_net_paid_pmpm_cost','total_cob_paid_pmpm_cost',\n",
    "                    'total_coins_pmpm_cost','total_copay_pmpm_cost','total_deduct_pmpm_cost','total_mbr_resp_pmpm_cost','total_ip_acute_admit_days_pmpm',\n",
    "                    'total_ip_ltach_admit_days_pmpm','total_ip_maternity_admit_days_pmpm','total_ip_mhsa_admit_days_pmpm','total_ip_rehab_admit_days_pmpm',    \n",
    "                    'total_ip_snf_admit_days_pmpm','atlas_recfacpth14','atlas_ffrpth14','atlas_fsrpth14','atlas_grocpth14','atlas_povertyallagespct',\n",
    "                    'cnt_cp_emails_pmpm_ct','cnt_cp_print_pmpm_ct', 'cnt_cp_vat_pmpm_ct','cnt_cp_webstatement_pmpm_ct', 'cms_frailty_ind', \n",
    "                    'cci_score', 'fci_score', 'dcsi_score','cms_tot_ma_payment_amt','cms_tot_partd_payment_amt','comp_physical_exam', 'telehealth',\n",
    "                           'rwjf_preventable_ip_rate','rwjf_healthcare_cost','rwjf_other_pcp','rwjf_pcp_rate','rwjf_dentists_ratio',\n",
    "                           'rwjf_men_hlth_prov_ratio','rwjf_age_gt_65_pct','rwjf_native_race_pct','rwjf_asian_race_pct','rwjf_age_lt_18_pct',\n",
    "                           'rwjf_female_pct','rwjf_hispanic_pct','rwjf_hawaiian_race_pct','rwjf_african_race_pct','rwjf_white_race_pct',\n",
    "                           'rwjf_non_english_pct','rwjf_rural_pct','rwjf_population','rwjf_food_insecurity_pct','rwjf_food_env_inx',\n",
    "                           'rwjf_poor_phy_hlth_days','rwjf_diabetes_pct','rwjf_hiv_rate','rwjf_median_house_income','rwjf_income_inequ_ratio',\n",
    "                           'rwjf_resident_seg_black_inx','rwjf_resident_seg_nonwhite_inx']]))\n",
    "\n",
    "print(\"Number of 1s:\", count_counter[1])\n",
    "print(\"Number of -1s:\", count_counter[-1])\n",
    "final_csv13_sdh.head(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only the inliers (where outlier is -1)\n",
    "final_csv13_cleaned = final_csv13_sdh[final_csv13_sdh['anomaly'] == 1].copy()\n",
    "\n",
    "# Drop the 'outlier' column since it's no longer needed\n",
    "final_csv13_cleaned.drop(columns=['anomaly'], inplace=True)\n",
    "\n",
    "# Display the cleaned data (without outliers)\n",
    "print(final_csv13_cleaned.head(1000))\n",
    "print(len(final_csv13_cleaned))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read only the specified columns\n",
    "sales_channel = pd.read_csv('Sales Channel.csv')\n",
    "\n",
    "# Display the DataFrame\n",
    "print('Sales Channel')\n",
    "print(sales_channel.head(1000))\n",
    "\n",
    "final_csv14_new_2 = pd.merge(final_csv13_cleaned, sales_channel, on='id', how='inner')\n",
    "\n",
    "print('final_csv14_new_2')\n",
    "print(final_csv14_new_2.head(1000))\n",
    "\n",
    "print('Length of final_csv14_new_2')\n",
    "print(len(final_csv14_new_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pandas if not already imported\n",
    "import pandas as pd\n",
    "\n",
    "# Set display option to show all rows\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "# Check for NaN values in the DataFrame\n",
    "print(final_csv13_cleaned.isnull().sum())\n",
    "\n",
    "# Optionally reset display setting to default after output\n",
    "# pd.reset_option('display.max_rows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#handles categorical data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Drop the 'id' column as it is not useful for prediction\n",
    "#final_csv13.drop(columns=['id'], inplace=True)\n",
    "\n",
    "# Handle categorical variables (Example: Label Encoding)\n",
    "categorical_columns = ['tenure_band','rucc_category','lang_spoken_cd','channel', 'sex_cd', 'race', 'state_of_residence', 'county_of_residence', 'hcc_model_type', 'cms_model_vers_cd','veteran_ind','dual_eligible_ind','disabled_ind','lis_ind']\n",
    "# Assuming your DataFrame has those categorical columns\n",
    "for col in categorical_columns:\n",
    "    if col in final_csv14_new_2.columns:\n",
    "        le = LabelEncoder()\n",
    "        final_csv14_new_2[col] = le.fit_transform(final_csv14_new_2[col].astype(str))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for NaN values in the DataFrame\n",
    "print(final_csv14_new_2.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SKIP THIS CODE!!!\n",
    "#Dropping duplicates to avoid data leakage\n",
    "#Use this later in the holdout code \n",
    "#duplicates = final_csv13_cleaned[final_csv13_cleaned['id'].duplicated(keep=False)]  # 'keep=False' shows all occurrences of duplicates\n",
    "\n",
    "# Display duplicates\n",
    "#print(\"Duplicates in the 'ID' column:\")\n",
    "#print(duplicates)\n",
    "\n",
    "#df_cleaned = final_csv13_cleaned.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest model training begins!\n",
    "X = final_csv13_cleaned.drop('preventive_visit_gap_ind', axis=1)  # Features\n",
    "y = final_csv13_cleaned['preventive_visit_gap_ind']  # Target variable\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)  # 0.5*30% = 15%\n",
    "\n",
    "# Create a Random Forest Classifier\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "X_train_cleaned = X_train.drop('id', axis=1)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_cleaned, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_cleaned = X_test.drop('id', axis=1)  # Drop 'id' for predictions\n",
    "\n",
    "# Predict probabilities for the positive class (1)\n",
    "y_pred_proba = model.predict_proba(X_test_cleaned)[:, 1]\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test_cleaned)\n",
    "\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"AUC:\", auc)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dont need to run everytime as this is simply for validation!\n",
    "X_val_cleaned = X_val.drop('id', axis=1)  # Drop 'id' for predictions\n",
    "\n",
    "# Predict probabilities for the positive class (1)\n",
    "y_pred_proba_val= model.predict_proba(X_val_cleaned)[:, 1]\n",
    "# Make predictions\n",
    "y_pred_val = model.predict(X_val_cleaned)\n",
    "\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_val, y_pred_val)\n",
    "auc = roc_auc_score(y_val, y_pred_proba_val)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"AUC:\", auc)\n",
    "print(classification_report(y_val, y_pred_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_pred)\n",
    "print(y_pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create submission DataFrame \n",
    "# Check the total count and for duplicates!\n",
    "submission_df = pd.DataFrame({\n",
    "    'ID': X_test['id'],         # The ID column\n",
    "    'SCORE': y_pred_proba       # The predicted probabilities\n",
    "})\n",
    "\n",
    "# Sort by SCORE in descending order\n",
    "submission_df.sort_values(by='SCORE', ascending=False, inplace=True)\n",
    "\n",
    "# Assign ranks based on SCORE, with ties getting the same rank\n",
    "submission_df['RANK'] = submission_df['SCORE'].rank(method='min', ascending=False)\n",
    "\n",
    "# Check the final output before saving  # Inspect the DataFrame\n",
    "\n",
    "# Save as CSV\n",
    "submission_df.to_csv('scored_file.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Run this after you've ran 'holdout-humana-Sharwari-20241005'\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Drop the 'id' column as it is not useful for prediction\n",
    "#final_csv13.drop(columns=['id'], inplace=True)\n",
    "\n",
    "df_holdout = pd.read_csv('holdout-output_file.csv')\n",
    "# Handle categorical variables (Example: Label Encoding)\n",
    "categorical_columns = ['tenure_band','rucc_category','lang_spoken_cd','channel', 'sex_cd', 'race', 'state_of_residence', 'county_of_residence', 'hcc_model_type', 'cms_model_vers_cd','veteran_ind','dual_eligible_ind','disabled_ind','lis_ind']\n",
    "# Assuming your DataFrame has those categorical columns\n",
    "for col in categorical_columns:\n",
    "    if col in final_csv13.columns:\n",
    "        le = LabelEncoder()\n",
    "        df_holdout[col] = le.fit_transform(df_holdout[col].astype(str))\n",
    "        \n",
    "print(df_holdout.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_holdout_unique = df_holdout.drop_duplicates()\n",
    "len(df_holdout_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_holdout = df_holdout.drop('id', axis=1)  # Drop 'id' for predictions\n",
    "\n",
    "# Predict probabilities for the positive class (1)\n",
    "y_pred_proba = model.predict_proba(X_holdout)[:, 1]\n",
    "\n",
    "# Create submission DataFrame\n",
    "holdout_submission_df1 = pd.DataFrame({\n",
    "    'ID': df_holdout['id'],         # The ID column\n",
    "    'SCORE': y_pred_proba       # The predicted probabilities\n",
    "})\n",
    "\n",
    "# Sort by SCORE in descending order\n",
    "holdout_submission_df1.sort_values(by='SCORE', ascending=False, inplace=True)\n",
    "\n",
    "# Assign ranks based on SCORE, with ties getting the same rank\n",
    "# Assign ranks based on SCORE, with ties getting the same rank\n",
    "holdout_submission_df1['RANK'] = holdout_submission_df1['SCORE'].rank(method='dense', ascending=False)\n",
    "\n",
    "\n",
    "# Check the final output before saving  # Inspect the DataFrame\n",
    "\n",
    "# Save as CSV\n",
    "holdout_submission_df1.to_csv('holdout_submission_scoredfile.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Manaswi final random forest code\n",
    "X_holdout = df_holdout_unique.drop('id', axis=1)  # Drop 'id' for predictions\n",
    "\n",
    "# Predict probabilities for the positive class (1)\n",
    "y_pred_proba = model.predict_proba(X_holdout)[:, 1]\n",
    "\n",
    "# Create submission DataFrame\n",
    "holdout_submission_df1 = pd.DataFrame({\n",
    "    'ID': df_holdout_unique['id'],         # The ID column\n",
    "    'SCORE': y_pred_proba       # The predicted probabilities\n",
    "})\n",
    "\n",
    "# Sort by SCORE in descending order\n",
    "holdout_submission_df1.sort_values(by='SCORE', ascending=False, inplace=True)\n",
    "\n",
    "# Assign ranks based on SCORE, with ties getting the same rank\n",
    "# Assign ranks based on SCORE, with ties getting the same rank\n",
    "holdout_submission_df1['RANK'] = holdout_submission_df1['SCORE'].rank(method='dense', ascending=False)\n",
    "\n",
    "\n",
    "# Check the final output before saving  # Inspect the DataFrame\n",
    "\n",
    "# Save as CSV\n",
    "holdout_submission_df1.to_csv('C:/Users/manas/Downloads/Humana Case Comp/Final score output/random_forest_scored_file-manaswi20241005.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import FileLink\n",
    "FileLink(r'holdout_submission_scoredfile.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming your DataFrame is named submission_df\n",
    "num_rows = len(holdout_submission_df1)\n",
    "print(\"Number of rows:\", num_rows)\n",
    "\n",
    "num_rows = len(df_holdout)\n",
    "print(\"Number of rows:\", num_rows)\n",
    "\n",
    "print(holdout_submission_df1.head(50000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming your DataFrame is named submission_df\n",
    "duplicates = holdout_submission_df1.duplicated()\n",
    "\n",
    "# Print the boolean Series\n",
    "print(duplicates)\n",
    "\n",
    "# Count the number of duplicate rows\n",
    "num_duplicates = duplicates.sum()\n",
    "print(\"Number of duplicate rows:\", num_duplicates)\n",
    "\n",
    "\n",
    "# Check for duplicates based on the 'ID' and 'SCORE' columns\n",
    "duplicates_specific = holdout_submission_df1.duplicated(subset=['ID', 'SCORE', 'RANK'])\n",
    "\n",
    "# Count the number of duplicate rows based on specific columns\n",
    "num_duplicates_specific = duplicates_specific.sum()\n",
    "print(\"Number of duplicate rows based on ID and SCORE and RANK:\", num_duplicates_specific)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fancy code dont run\n",
    "from IPython.display import FileLink\n",
    "FileLink(r'output_file.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Manaswi xgboost code-1\n",
    "import xgboost as xgb\n",
    "\n",
    "X = df_holdout_unique.drop('id', axis=1)  # Features\n",
    "\n",
    "# Load your data into DMatrix\n",
    "dholdout = xgb.DMatrix(data=X)\n",
    "\n",
    "# Run the code to predictions\n",
    "predictions = bst.predict(dholdout)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Manaswi xgboost code-2\n",
    "# Create submission DataFrame\n",
    "submission_df = pd.DataFrame({\n",
    "    'ID': df_holdout_unique['id'],         # The ID column\n",
    "    'SCORE': predictions       # The predicted probabilities\n",
    "})\n",
    "\n",
    "# Sort by SCORE in descending order\n",
    "submission_df.sort_values(by='SCORE', ascending=False, inplace=True)\n",
    "\n",
    "# Assign ranks based on SCORE, with ties getting the same rank\n",
    "submission_df['RANK'] = submission_df['SCORE'].rank(method='min', ascending=False)\n",
    "\n",
    "# Check the final output before saving  # Inspect the DataFrame\n",
    "\n",
    "# Save as CSV\n",
    "submission_df.to_csv('C:/Users/manas/Downloads/Humana Case Comp/Final score output/xgboost_scored_file-manaswi20241005.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create submission DataFrame\n",
    "submission_df = pd.DataFrame({\n",
    "    'ID': X_test['id'],         # The ID column\n",
    "    'SCORE': y_pred_proba       # The predicted probabilities\n",
    "})\n",
    "\n",
    "# Sort by SCORE in descending order\n",
    "submission_df.sort_values(by='SCORE', ascending=False, inplace=True)\n",
    "\n",
    "# Assign ranks based on SCORE, with ties getting the same rank\n",
    "submission_df['RANK'] = submission_df['SCORE'].rank(method='min', ascending=False)\n",
    "\n",
    "# Check the final output before saving  # Inspect the DataFrame\n",
    "\n",
    "# Save as CSV\n",
    "submission_df.to_csv('scored_file.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##XGBoost model training starts here!\n",
    "## Added a loop to run the loop 5000 time and print accuracy\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "# Prepare the data (as in your code)\n",
    "X = final_csv13_cleaned.drop('preventive_visit_gap_ind', axis=1)  # Features\n",
    "y = final_csv13_cleaned['preventive_visit_gap_ind']  # Target variable\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train_cleaned = X_train.drop('id', axis=1)\n",
    "X_test_cleaned = X_test.drop('id', axis=1)\n",
    "\n",
    "# Load your data into DMatrix\n",
    "dtrain = xgb.DMatrix(data=X_train_cleaned, label=y_train)\n",
    "dtest = xgb.DMatrix(data=X_test_cleaned, label=y_test)\n",
    "\n",
    "# Define parameters\n",
    "params = {\n",
    "    'objective': 'binary:logistic',  # Use logistic regression for binary classification\n",
    "    'tree_method': 'hist',           # Use 'gpu_hist' if using a GPU\n",
    "    'max_depth': 6,                  # Limit tree depth to prevent overfitting\n",
    "    'learning_rate': 0.1,            # Shrinkage\n",
    "    'subsample': 0.8,                # Row subsampling\n",
    "    'colsample_bytree': 0.8,         # Feature subsampling\n",
    "    'eval_metric': 'auc'             # Performance metric (e.g., AUC for classification)\n",
    "}\n",
    "\n",
    "# Train the model with early stopping\n",
    "bst = xgb.train(params, dtrain, num_boost_round=2000, evals=[(dtest, 'test')],\n",
    "                early_stopping_rounds=10)\n",
    "\n",
    "# Make predictions (predicted probabilities)\n",
    "y_pred_proba = bst.predict(dtest)\n",
    "\n",
    "# Convert probabilities to binary predictions using 0.5 as the threshold\n",
    "y_pred = [1 if prob > 0.5 else 0 for prob in y_pred_proba]\n",
    "\n",
    "# Evaluate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Calculate AUC using predicted probabilities\n",
    "auc = roc_auc_score(y_test, y_pred_proba)\n",
    "print(f\"AUC: {auc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Run this after you've ran 'holdout-feature-engg-manaswi'\n",
    "df_holdout = pd.read_csv('C:/Users/manas/Downloads/Humana Case Comp/Holdout_final/cleaned_output_file_Holdout_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Manaswi xgboost code-1\n",
    "import xgboost as xgb\n",
    "\n",
    "X = df_holdout.drop('id', axis=1)  # Features\n",
    "\n",
    "# Load your data into DMatrix\n",
    "dholdout = xgb.DMatrix(data=X)\n",
    "\n",
    "# Run the code to predictions\n",
    "predictions = bst.predict(dholdout)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Manaswi xgboost code-2\n",
    "# Create submission DataFrame\n",
    "submission_df = pd.DataFrame({\n",
    "    'ID': df_holdout['id'],         # The ID column\n",
    "    'SCORE': predictions       # The predicted probabilities\n",
    "})\n",
    "\n",
    "# Sort by SCORE in descending order\n",
    "submission_df.sort_values(by='SCORE', ascending=False, inplace=True)\n",
    "\n",
    "# Assign ranks based on SCORE, with ties getting the same rank\n",
    "submission_df['RANK'] = submission_df['SCORE'].rank(method='min', ascending=False)\n",
    "\n",
    "# Check the final output before saving  # Inspect the DataFrame\n",
    "\n",
    "# Save as CSV\n",
    "submission_df.to_csv('C:/Users/manas/Downloads/Humana Case Comp/Final score output/xgboost_scored_file-manaswi20241006.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameter optimization for XGBoost to find optimal parameter value\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define a classifier with initial hyperparameters\n",
    "xgb_model = XGBClassifier(tree_method='hist', eval_metric='auc')\n",
    "\n",
    "# Set up a parameter grid for hyperparameter tuning\n",
    "param_grid = {\n",
    "    'max_depth': [3, 6, 10],\n",
    "    'learning_rate': [0.01, 0.1, 0.3],\n",
    "    'n_estimators': [100, 500, 1000],\n",
    "    'subsample': [0.7, 0.8, 1.0],\n",
    "    'colsample_bytree': [0.7, 0.8, 1.0]\n",
    "}\n",
    "\n",
    "# Use GridSearchCV to find the best parameters\n",
    "grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid, \n",
    "                           scoring='roc_auc', cv=3, verbose=1)\n",
    "\n",
    "# Fit the model to the training data\n",
    "grid_search.fit(X_train_cleaned, y_train)\n",
    "\n",
    "# Get the best parameters from the search\n",
    "print(f\"Best Parameters: {grid_search.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(bst, X_train_cleaned, y_train, cv=5, scoring='accuracy')\n",
    "print(f\"Cross-Validation Scores: {scores}\")\n",
    "print(f\"Mean CV Score: {scores.mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameter optimization for XGBoost to find optimal hyperparameter value \n",
    "from bayes_opt import BayesianOptimization\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Prepare the data (as in your code)\n",
    "X = final_csv14_new_2.drop('preventive_visit_gap_ind', axis=1)  # Features\n",
    "y = final_csv14_new_2['preventive_visit_gap_ind']  # Target variable\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train_cleaned = X_train.drop('id', axis=1)\n",
    "X_test_cleaned = X_test.drop('id', axis=1)\n",
    "\n",
    "# Load your data into DMatrix\n",
    "#dtrain = xgb.DMatrix(data=X_train_cleaned, label=y_train)\n",
    "#dtest = xgb.DMatrix(data=X_test_cleaned, label=y_test)\n",
    "\n",
    "def xgb_evaluate(learning_rate, max_depth, subsample):\n",
    "    params = {\n",
    "        'learning_rate': learning_rate,\n",
    "        'max_depth': int(max_depth),\n",
    "        'subsample': subsample,\n",
    "        'n_estimators': 700,\n",
    "        'objective': 'binary:logistic'\n",
    "    }\n",
    "    model = XGBClassifier(**params)\n",
    "    model.fit(X_train, y_train)\n",
    "    return model.score(X_test, y_test)\n",
    "\n",
    "optimizer = BayesianOptimization(f=xgb_evaluate, pbounds={'learning_rate': (0.01, 0.2), 'max_depth': (3, 10), 'subsample': (0.6, 1.0)}, random_state=42)\n",
    "optimizer.maximize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##New XGBoost model training starts here with optimized hyperparameters from the above step!\n",
    "## Added a loop to run the loop 5000 time and print accuracy\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "# Prepare the data (as in your code)\n",
    "X = final_csv14_new_2.drop('preventive_visit_gap_ind', axis=1)  # Features\n",
    "y = final_csv14_new_2['preventive_visit_gap_ind']  # Target variable\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train_cleaned = X_train.drop('id', axis=1)\n",
    "X_test_cleaned = X_test.drop('id', axis=1)\n",
    "\n",
    "# Load your data into DMatrix\n",
    "dtrain = xgb.DMatrix(data=X_train_cleaned, label=y_train)\n",
    "dtest = xgb.DMatrix(data=X_test_cleaned, label=y_test)\n",
    "\n",
    "# Define parameters\n",
    "params = {\n",
    "    'objective': 'binary:logistic',  # Use logistic regression for binary classification\n",
    "    'tree_method': 'hist',           # Use 'gpu_hist' if using a GPU\n",
    "    'max_depth': 10,                  # Limit tree depth to prevent overfitting\n",
    "    'learning_rate': 0.08116,            # Shrinkage\n",
    "    'subsample': 0.8928,                # Row subsampling\n",
    "    'colsample_bytree': 0.8,         # Feature subsampling\n",
    "    'eval_metric': 'auc'             # Performance metric (e.g., AUC for classification)\n",
    "}\n",
    "\n",
    "# Train the model with early stopping\n",
    "bst = xgb.train(params, dtrain, num_boost_round=2000, evals=[(dtest, 'test')],\n",
    "                early_stopping_rounds=10)\n",
    "\n",
    "# Make predictions (predicted probabilities)\n",
    "y_pred_proba = bst.predict(dtest)\n",
    "\n",
    "# Convert probabilities to binary predictions using 0.5 as the threshold\n",
    "y_pred = [1 if prob > 0.5 else 0 for prob in y_pred_proba]\n",
    "\n",
    "# Evaluate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Calculate AUC using predicted probabilities\n",
    "auc = roc_auc_score(y_test, y_pred_proba)\n",
    "print(f\"AUC: {auc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model Stacking\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Define base models\n",
    "xgb_model = XGBClassifier(n_estimators=100, learning_rate=0.05)\n",
    "rf_model = RandomForestClassifier(n_estimators=100)\n",
    "svm_model = SVC(probability=True, kernel='linear')\n",
    "\n",
    "# Define the meta-model\n",
    "meta_model = LogisticRegression()\n",
    "\n",
    "# Define stacking classifier\n",
    "stacking_clf = StackingClassifier(\n",
    "    estimators=[\n",
    "        ('xgb', xgb_model),\n",
    "        ('rf', rf_model),\n",
    "        ('svm', svm_model)\n",
    "    ],\n",
    "    final_estimator=meta_model,\n",
    "    cv=5\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "stacking_clf.fit(X_train_cleaned, y_train)\n",
    "\n",
    "# Predict probabilities\n",
    "y_pred = stacking_clf.predict_proba(X_test_cleaned)[:, 1]\n",
    "\n",
    "# Calculate AUC\n",
    "auc_score = roc_auc_score(y_test, y_pred)\n",
    "print(f\"AUC Score: {auc_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using SMOTE with XGBoost\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "##New XGBoost model training starts here with optimized hyperparameters from the above step!\n",
    "## Added a loop to run the loop 5000 time and print accuracy\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "# Prepare the data (as in your code)\n",
    "X = final_csv14_new_2.drop('preventive_visit_gap_ind', axis=1)  # Features\n",
    "y = final_csv14_new_2['preventive_visit_gap_ind']  # Target variable\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train_cleaned = X_train.drop('id', axis=1)\n",
    "X_test_cleaned = X_test.drop('id', axis=1)\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train_cleaned, y_train)\n",
    "\n",
    "# Load your data into DMatrix\n",
    "dtrain = xgb.DMatrix(data=X_resampled, label=y_resampled)\n",
    "dtest = xgb.DMatrix(data=X_test_cleaned, label=y_test)\n",
    "\n",
    "# Define parameters\n",
    "params = {\n",
    "    'objective': 'binary:logitraw',  # Use logistic regression for binary classification\n",
    "    'tree_method': 'hist',           # Use 'gpu_hist' if using a GPU\n",
    "    'max_depth': 9,                  # Limit tree depth to prevent overfitting\n",
    "    'learning_rate': 0.2,            # Shrinkage\n",
    "    'subsample': 0.8894,                # Row subsampling\n",
    "    'colsample_bytree': 0.8,         # Feature subsampling\n",
    "    'eval_metric': 'auc'             # Performance metric (e.g., AUC for classification)\n",
    "}\n",
    "\n",
    "# Train the model with early stopping\n",
    "bst = xgb.train(params, dtrain, num_boost_round=2000, evals=[(dtest, 'test')],\n",
    "                early_stopping_rounds=10)\n",
    "\n",
    "# Make predictions (predicted probabilities)\n",
    "y_pred_proba = bst.predict(dtest)\n",
    "\n",
    "# Convert probabilities to binary predictions using 0.5 as the threshold\n",
    "y_pred = [1 if prob > 0.5 else 0 for prob in y_pred_proba]\n",
    "\n",
    "# Evaluate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Calculate AUC using predicted probabilities\n",
    "auc = roc_auc_score(y_test, y_pred_proba)\n",
    "print(f\"AUC: {auc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using ADASYN-Advanced SMOTE with XGBoost\n",
    "from imblearn.over_sampling import ADASYN\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "##New XGBoost model training starts here with optimized hyperparameters from the above step!\n",
    "## Added a loop to run the loop 5000 time and print accuracy\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "# Prepare the data (as in your code)\n",
    "X = final_csv14_new_2.drop('preventive_visit_gap_ind', axis=1)  # Features\n",
    "y = final_csv14_new_2['preventive_visit_gap_ind']  # Target variable\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train_cleaned = X_train.drop('id', axis=1)\n",
    "X_test_cleaned = X_test.drop('id', axis=1)\n",
    "\n",
    "adasyn = ADASYN(random_state=42)\n",
    "X_resampled, y_resampled = adasyn.fit_resample(X_train, y_train)\n",
    "\n",
    "# Load your data into DMatrix\n",
    "dtrain = xgb.DMatrix(data=X_resampled, label=y_resampled)\n",
    "dtest = xgb.DMatrix(data=X_test_cleaned, label=y_test)\n",
    "\n",
    "# Define parameters\n",
    "params = {\n",
    "    'objective': 'binary:logitraw',  # Use logistic regression for binary classification\n",
    "    'tree_method': 'hist',           # Use 'gpu_hist' if using a GPU\n",
    "    'max_depth': 9,                  # Limit tree depth to prevent overfitting\n",
    "    'learning_rate': 0.2,            # Shrinkage\n",
    "    'subsample': 0.8894,                # Row subsampling\n",
    "    'colsample_bytree': 0.8,         # Feature subsampling\n",
    "    'eval_metric': 'auc'             # Performance metric (e.g., AUC for classification)\n",
    "}\n",
    "\n",
    "# Train the model with early stopping\n",
    "bst = xgb.train(params, dtrain, num_boost_round=2000, evals=[(dtest, 'test')],\n",
    "                early_stopping_rounds=10)\n",
    "\n",
    "# Make predictions (predicted probabilities)\n",
    "y_pred_proba = bst.predict(dtest)\n",
    "\n",
    "# Convert probabilities to binary predictions using 0.5 as the threshold\n",
    "y_pred = [1 if prob > 0.5 else 0 for prob in y_pred_proba]\n",
    "\n",
    "# Evaluate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Calculate AUC using predicted probabilities\n",
    "auc = roc_auc_score(y_test, y_pred_proba)\n",
    "print(f\"AUC: {auc}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 5806878,
     "sourceId": 9534328,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5808557,
     "sourceId": 9536525,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5814785,
     "sourceId": 9544670,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5817282,
     "sourceId": 9547953,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5819504,
     "sourceId": 9551295,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30775,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
